{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qluARFuhbbx5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJnJMoRUbjTP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nbyrv3SCgwE"
   },
   "source": [
    "## We read the data from the given csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEb8uEFQb060"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/drive/My Drive/SMAI_Assignment3_Dataset/dataset_q4/household_power_consumption.txt\", sep=';')\n",
    "data\n",
    "X = pd.DataFrame()\n",
    "X['row_no'] = np.arange(len(data))\n",
    "X['data'] = data['Global_active_power']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIn8SBQCyFXf"
   },
   "source": [
    "# Window size = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TR6y3fauyN99"
   },
   "source": [
    "## We train our dataset for 50,000 samples using a window size of 60. In this phase, we ignore the rows having missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "X2 = np.array([0] * (window_size + 1))\n",
    "\n",
    "count = 1\n",
    "while(count<=50000):\n",
    "  row = random.randrange(len(X) - window_size - 1)\n",
    "  temp = X[row:row+window_size+1]['data'].tolist()\n",
    "  if('?' not in temp):\n",
    "    temp = [float(item) for item in temp]\n",
    "    X2 = np.vstack((X2,temp)) \n",
    "    count = count + 1\n",
    "\n",
    "X2 = X2[1:,:]\n",
    "# print(X2)\n",
    "# print(X2.shape)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufAFjp0_ypcw"
   },
   "source": [
    "## We split our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X2[0:35000,0:60]\n",
    "y_train = X2[0:35000,60]\n",
    "\n",
    "X_test = X2[35000:,0:60]\n",
    "y_test = X2[35000:,60]\n",
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1QcEbIyy6G_"
   },
   "source": [
    "## Linear Regression model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "W9WUB2_JYXDY",
    "outputId": "4da69944-a204-4bb9-83a6-a34bc63e62d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.0653094713737575\n",
      "r2 score:  0.9429255892493377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train, y_train)\n",
    "y_pred_reg = model_reg.predict(X_test)\n",
    "\n",
    "mse_reg = mean_squared_error(y_test, y_pred_reg)\n",
    "print('Mean squared error: ', mse_reg)\n",
    "\n",
    "r2_reg = r2_score(y_test, y_pred_reg)\n",
    "print('r2 score: ', r2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWLtJtcyy95N"
   },
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLpWvN7TB2eo"
   },
   "source": [
    "## MLP model 1\n",
    "## In this model, we use MLP having one hidden layer of 100 nodes using activation function 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "f0xkz3iWZC-o",
    "outputId": "d3774c30-dd42-4e1e-d88c-b855c14cd1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.1208 - mse: 0.1208\n",
      "Epoch 2/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0867 - mse: 0.0867\n",
      "Epoch 3/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0802 - mse: 0.0801\n",
      "Epoch 4/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0767 - mse: 0.0767\n",
      "Epoch 5/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0765 - mse: 0.0764\n",
      "Epoch 6/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0734 - mse: 0.0734\n",
      "Epoch 7/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0731 - mse: 0.0731\n",
      "Epoch 8/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0744 - mse: 0.0744\n",
      "Epoch 9/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0720 - mse: 0.0720\n",
      "Epoch 10/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0719 - mse: 0.0720\n",
      "Epoch 11/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0709 - mse: 0.0709\n",
      "Epoch 12/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0710 - mse: 0.0710\n",
      "Epoch 13/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0692 - mse: 0.0692\n",
      "Epoch 14/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0692 - mse: 0.0692\n",
      "Epoch 15/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0682 - mse: 0.0682\n",
      "Epoch 16/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0671 - mse: 0.0671\n",
      "Epoch 17/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0677 - mse: 0.0677\n",
      "Epoch 18/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0687 - mse: 0.0687\n",
      "Epoch 19/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0672 - mse: 0.0671\n",
      "Epoch 20/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0668 - mse: 0.0668\n",
      "Epoch 21/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0662 - mse: 0.0662\n",
      "Epoch 22/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0662 - mse: 0.0661\n",
      "Epoch 23/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0663 - mse: 0.0663\n",
      "Epoch 24/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0648 - mse: 0.0648\n",
      "Epoch 25/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0654 - mse: 0.0653\n",
      "Epoch 26/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0659 - mse: 0.0659\n",
      "Epoch 27/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0658 - mse: 0.0658\n",
      "Epoch 28/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0651 - mse: 0.0651\n",
      "Epoch 29/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0647 - mse: 0.0647\n",
      "Epoch 30/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0648 - mse: 0.0648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f27259bc320>"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(100, input_dim=60, activation='relu'))\n",
    "model_nn.add(Dense(1))\n",
    "model_nn.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_nn.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CdrUs3H7d_w5",
    "outputId": "1f8cba9c-b33e-4598-881a-215119ad83ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.06743341996900627\n",
      "r2 score:  0.941069455491268\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn1 = model_nn.predict(X_test)\n",
    "mse_nn1 = mean_squared_error(y_test, y_pred_nn1)\n",
    "print('Mean squared error: ', mse_nn1)\n",
    "\n",
    "r2_nn1 = r2_score(y_test, y_pred_nn1)\n",
    "print('r2 score: ', r2_nn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6H8KgMxzSFG"
   },
   "source": [
    "## MLP model 2\n",
    "### In this model we add another hidden layer in our model and test the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RKQoVBZnfu5f",
    "outputId": "aed83012-f16a-44bf-c86b-32291db2c1ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.1194 - mse: 0.1194\n",
      "Epoch 2/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0816 - mse: 0.0816\n",
      "Epoch 3/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0768\n",
      "Epoch 4/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0747\n",
      "Epoch 5/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0730 - mse: 0.0730\n",
      "Epoch 6/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
      "Epoch 7/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0703 - mse: 0.0703\n",
      "Epoch 8/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0697 - mse: 0.0698\n",
      "Epoch 9/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
      "Epoch 10/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0682 - mse: 0.0682\n",
      "Epoch 11/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
      "Epoch 12/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0678 - mse: 0.0678\n",
      "Epoch 13/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0687 - mse: 0.0686\n",
      "Epoch 14/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0667 - mse: 0.0667\n",
      "Epoch 15/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0656 - mse: 0.0656\n",
      "Epoch 16/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0669 - mse: 0.0669\n",
      "Epoch 17/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0658 - mse: 0.0658\n",
      "Epoch 18/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0659 - mse: 0.0658\n",
      "Epoch 19/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0652 - mse: 0.0652\n",
      "Epoch 20/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0652 - mse: 0.0652\n",
      "Epoch 21/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0644 - mse: 0.0644\n",
      "Epoch 22/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0637 - mse: 0.0636\n",
      "Epoch 23/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0636 - mse: 0.0636\n",
      "Epoch 24/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0638 - mse: 0.0638\n",
      "Epoch 25/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
      "Epoch 26/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0628 - mse: 0.0628\n",
      "Epoch 27/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0632 - mse: 0.0632\n",
      "Epoch 28/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
      "Epoch 29/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
      "Epoch 30/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0619 - mse: 0.0618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f273bcccd68>"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn1 = Sequential()\n",
    "model_nn1.add(Dense(100, input_dim=60, activation='relu'))\n",
    "model_nn1.add(Dense(100, input_dim=60, activation='relu'))\n",
    "model_nn1.add(Dense(1))\n",
    "model_nn1.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_nn1.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "eqqGIfW4S-ZC",
    "outputId": "af524d74-f043-4f1c-8c82-28338c5ef929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.069224194734125\n",
      "r2 score:  0.9395044847089845\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn2 = model_nn1.predict(X_test)\n",
    "mse_nn2 = mean_squared_error(y_test, y_pred_nn2)\n",
    "print('Mean squared error: ', mse_nn2)\n",
    "\n",
    "r2_nn2 = r2_score(y_test, y_pred_nn2)\n",
    "print('r2 score: ', r2_nn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "603Bv7Rg4_t2"
   },
   "source": [
    "## MLP model 3\n",
    "### In this model we change the activation function to 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NQcBsE6_4V0n",
    "outputId": "62965b37-1e74-48af-e0be-1dd9a3a803fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.1363 - mse: 0.1363\n",
      "Epoch 2/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0831 - mse: 0.0831\n",
      "Epoch 3/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0772 - mse: 0.0772\n",
      "Epoch 4/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0745 - mse: 0.0745\n",
      "Epoch 5/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0735 - mse: 0.0735\n",
      "Epoch 6/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0739 - mse: 0.0739\n",
      "Epoch 7/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0735 - mse: 0.0735\n",
      "Epoch 8/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0739 - mse: 0.0739\n",
      "Epoch 9/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0735 - mse: 0.0735\n",
      "Epoch 10/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0738 - mse: 0.0737\n",
      "Epoch 11/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0732 - mse: 0.0732\n",
      "Epoch 12/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0727 - mse: 0.0727\n",
      "Epoch 13/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0731 - mse: 0.0731\n",
      "Epoch 14/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0731 - mse: 0.0730\n",
      "Epoch 15/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0719 - mse: 0.0719\n",
      "Epoch 16/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0719 - mse: 0.0719\n",
      "Epoch 17/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0718 - mse: 0.0718\n",
      "Epoch 18/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0727 - mse: 0.0727\n",
      "Epoch 19/30\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
      "Epoch 20/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0710 - mse: 0.0710\n",
      "Epoch 21/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0714 - mse: 0.0714\n",
      "Epoch 22/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0710 - mse: 0.0710\n",
      "Epoch 23/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0719 - mse: 0.0719\n",
      "Epoch 24/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0716 - mse: 0.0716\n",
      "Epoch 25/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0707 - mse: 0.0707\n",
      "Epoch 26/30\n",
      "1094/1094 [==============================] - 1s 1ms/step - loss: 0.0708 - mse: 0.0708\n",
      "Epoch 27/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0706 - mse: 0.0706\n",
      "Epoch 28/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0729 - mse: 0.0729\n",
      "Epoch 29/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0704 - mse: 0.0704\n",
      "Epoch 30/30\n",
      "1094/1094 [==============================] - 2s 1ms/step - loss: 0.0709 - mse: 0.0709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f272cd9f400>"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn3 = Sequential()\n",
    "model_nn3.add(Dense(100, input_dim=60, activation='sigmoid'))\n",
    "model_nn3.add(Dense(1))\n",
    "model_nn3.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_nn3.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "b2aDpOJ64OVf",
    "outputId": "66286d31-11ed-4408-982b-2d9e01e8d8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.076219229660009\n",
      "r2 score:  0.9314961160221193\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn3 = model_nn3.predict(X_test)\n",
    "mse_nn3 = mean_squared_error(y_test, y_pred_nn3)\n",
    "print('Mean squared error: ', mse_nn3)\n",
    "\n",
    "r2_nn3 = r2_score(y_test, y_pred_nn3)\n",
    "print('r2 score: ', r2_nn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5vHGv0Gzp9S"
   },
   "source": [
    "# Summary of the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "YMrheeZmzpbX",
    "outputId": "84f0c875-bf78-4ccf-d373-e1ae62b6d9ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean squared error</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression model 1</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.942926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP model 1</td>\n",
       "      <td>0.067433</td>\n",
       "      <td>0.941069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP model 2</td>\n",
       "      <td>0.069224</td>\n",
       "      <td>0.939504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP model 3</td>\n",
       "      <td>0.076219</td>\n",
       "      <td>0.931496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Mean squared error  r2 score\n",
       "0  Linear Regression model 1            0.065309  0.942926\n",
       "1                MLP model 1            0.067433  0.941069\n",
       "2                MLP model 2            0.069224  0.939504\n",
       "3                MLP model 3            0.076219  0.931496"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l1 = [\"Linear Regression model 1\", mse_reg, r2_reg]\n",
    "mlp_l2 = [\"MLP model 1\", mse_nn1, r2_nn1]\n",
    "mlp_l3 = [\"MLP model 2\", mse_nn2, r2_nn2]\n",
    "mlp_l4 = [\"MLP model 3\", mse_nn3, r2_nn3]\n",
    "data = [lr_l1, mlp_l2, mlp_l3, mlp_l4]\n",
    "df = pd.DataFrame(data, columns = ['Model', 'Mean squared error', 'r2 score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSLcq3Gi0ucC"
   },
   "source": [
    "# Window size = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOQhHqI207GH"
   },
   "source": [
    "## We train our dataset for 50,000 samples using a window size of 120. In this phase, we ignore the rows having missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 120\n",
    "X2 = np.array([0] * (window_size + 1))\n",
    "\n",
    "count = 1\n",
    "while(count<=30000):\n",
    "  row = random.randrange(len(X) - window_size - 1)\n",
    "  temp = X[row:row+window_size+1]['data'].tolist()\n",
    "  if('?' not in temp):\n",
    "    temp = [float(item) for item in temp]\n",
    "    X2 = np.vstack((X2,temp)) \n",
    "    count = count + 1\n",
    "\n",
    "X2 = X2[1:,:]\n",
    "# print(X2)\n",
    "# print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJxxS4AE07G1"
   },
   "source": [
    "## We split our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X2[0:21000,0:120]\n",
    "y_train = X2[0:21000,120]\n",
    "\n",
    "X_test = X2[21000:,0:120]\n",
    "y_test = X2[21000:,120]\n",
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbFs3W_f07HE"
   },
   "source": [
    "## Linear Regression model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "g49Yg12707HG",
    "outputId": "ada43aa9-66c8-42b7-f946-2f7185f89eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.0737459290811239\n",
      "r2 score:  0.9337122808870182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_reg2 = LinearRegression()\n",
    "model_reg2.fit(X_train, y_train)\n",
    "y_pred_reg2 = model_reg2.predict(X_test)\n",
    "\n",
    "mse_reg2 = mean_squared_error(y_test, y_pred_reg2)\n",
    "print('Mean squared error: ', mse_reg2)\n",
    "\n",
    "r2_reg2 = r2_score(y_test, y_pred_reg2)\n",
    "print('r2 score: ', r2_reg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMZVhkTe07HO"
   },
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-JF5MY8BeCM"
   },
   "source": [
    "## MLP model 4\n",
    "## In this model, we use MLP having one hidden layer of 100 nodes using activation function 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xzB2RZXg07HQ",
    "outputId": "e5c361ed-bb70-49d5-bf5b-93599a7c49ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2022 - mse: 0.2022\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.1123 - mse: 0.1117\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0989 - mse: 0.0988\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0953 - mse: 0.0953\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0928 - mse: 0.0927\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0861 - mse: 0.0861\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0848 - mse: 0.0847\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0957 - mse: 0.0958\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0834 - mse: 0.0834\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0837 - mse: 0.0838\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0826 - mse: 0.0826\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0824 - mse: 0.0823\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0836 - mse: 0.0837\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0818 - mse: 0.0812\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0833 - mse: 0.0834\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0781 - mse: 0.0782\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0788 - mse: 0.0789\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0770 - mse: 0.0770\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0741 - mse: 0.0742\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0752 - mse: 0.0753\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0744 - mse: 0.0743\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0722 - mse: 0.0723\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0731 - mse: 0.0731\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0725 - mse: 0.0725\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0711 - mse: 0.0712\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0709 - mse: 0.0709\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0720 - mse: 0.0720\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0703 - mse: 0.0704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f273aec0240>"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn4 = Sequential()\n",
    "model_nn4.add(Dense(100, input_dim=120, activation='relu'))\n",
    "model_nn4.add(Dense(1))\n",
    "model_nn4.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_nn4.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ODsU6DNA07HX",
    "outputId": "0237aaad-60ff-4c66-ec82-c0b9ca824e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.07395400051487365\n",
      "r2 score:  0.9335252525191111\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn4 = model_nn4.predict(X_test)\n",
    "mse_nn4 = mean_squared_error(y_test, y_pred_nn4)\n",
    "print('Mean squared error: ', mse_nn4)\n",
    "\n",
    "r2_nn4 = r2_score(y_test, y_pred_nn4)\n",
    "print('r2 score: ', r2_nn4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mg8okS6c07He"
   },
   "source": [
    "## MLP model 5\n",
    "### In this model we add another hidden layer in our model and test the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Xw0DEo_V07Hg",
    "outputId": "8f7b683f-df46-436a-ed94-5681bd1e5658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.1632 - mse: 0.1634\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.1075 - mse: 0.1076\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0920 - mse: 0.0921\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0877 - mse: 0.0878\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0863 - mse: 0.0863\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0827 - mse: 0.0828\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0812 - mse: 0.0813\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0818 - mse: 0.0819\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0787 - mse: 0.0785\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0808 - mse: 0.0809\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0801 - mse: 0.0800\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0760 - mse: 0.0760\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0756 - mse: 0.0757\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0771 - mse: 0.0772\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0750 - mse: 0.0750\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0747 - mse: 0.0748\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0731 - mse: 0.0731\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0740 - mse: 0.0740\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0716 - mse: 0.0717\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0729 - mse: 0.0730\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0701 - mse: 0.0702\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0724 - mse: 0.0725\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0721 - mse: 0.0722\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0699 - mse: 0.0698\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0700 - mse: 0.0700\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0686 - mse: 0.0684\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0712 - mse: 0.0713\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0671 - mse: 0.0672\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0671 - mse: 0.0669\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0670 - mse: 0.0671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f272d0d60f0>"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn5 = Sequential()\n",
    "model_nn5.add(Dense(100, input_dim=120, activation='relu'))\n",
    "model_nn5.add(Dense(100, input_dim=120, activation='relu'))\n",
    "model_nn5.add(Dense(1))\n",
    "model_nn5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_nn5.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "rBaIQMng07Hn",
    "outputId": "aee2b07b-43b9-47c3-feb3-d4e8784c466b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.08150738651148945\n",
      "r2 score:  0.9267357695532811\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn5 = model_nn5.predict(X_test)\n",
    "mse_nn5 = mean_squared_error(y_test, y_pred_nn5)\n",
    "print('Mean squared error: ', mse_nn5)\n",
    "\n",
    "r2_nn5 = r2_score(y_test, y_pred_nn5)\n",
    "print('r2 score: ', r2_nn5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvmkY-jv7Bc4"
   },
   "source": [
    "## MLP model 6\n",
    "### In this model we change the activation function to 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "60vSS4TF322z",
    "outputId": "a4d57ee5-ec18-4574-eeb3-c7a4607c1e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2167 - mse: 0.2169\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.1117 - mse: 0.1118\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0960 - mse: 0.0961\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0920 - mse: 0.0918\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0895 - mse: 0.0894\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0878 - mse: 0.0879\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0854 - mse: 0.0852\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0833 - mse: 0.0831\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0846 - mse: 0.0847\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0852 - mse: 0.0849\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0817 - mse: 0.0818\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0810 - mse: 0.0811\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0850 - mse: 0.0851\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0817 - mse: 0.0818\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0820 - mse: 0.0821\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0807 - mse: 0.0807\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0821 - mse: 0.0821\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0813 - mse: 0.0813\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0815 - mse: 0.0815\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0820 - mse: 0.0818\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0797 - mse: 0.0798\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0802 - mse: 0.0803\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0790 - mse: 0.0791\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0777 - mse: 0.0778\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0788 - mse: 0.0788\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0795 - mse: 0.0796\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0795 - mse: 0.0796\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0791 - mse: 0.0792\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0782 - mse: 0.0783\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0762 - mse: 0.0763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2736d9ceb8>"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn6 = Sequential()\n",
    "model_nn6.add(Dense(100, input_dim=120, activation='sigmoid'))\n",
    "model_nn6.add(Dense(1))\n",
    "model_nn6.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_nn6.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z_ggjvry4BQk",
    "outputId": "b9a620a6-c181-4b47-b0c2-f714c9407aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.08456300210476338\n",
      "r2 score:  0.9239891801389505\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn6 = model_nn6.predict(X_test)\n",
    "mse_nn6 = mean_squared_error(y_test, y_pred_nn6)\n",
    "print('Mean squared error: ', mse_nn6)\n",
    "\n",
    "r2_nn6 = r2_score(y_test, y_pred_nn6)\n",
    "print('r2 score: ', r2_nn6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbwQQTAq07Ht"
   },
   "source": [
    "# Summary of the three models having window size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "cPK6bgRN5pC0",
    "outputId": "24fd5f5c-1b52-44b1-cafd-b67290c2f594"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean squared error</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression model 2</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.942926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP model 4</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.933525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP model 5</td>\n",
       "      <td>0.081507</td>\n",
       "      <td>0.926736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP model 6</td>\n",
       "      <td>0.084563</td>\n",
       "      <td>0.923989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Mean squared error  r2 score\n",
       "0  Linear Regression model 2            0.065309  0.942926\n",
       "1                MLP model 4            0.073954  0.933525\n",
       "2                MLP model 5            0.081507  0.926736\n",
       "3                MLP model 6            0.084563  0.923989"
      ]
     },
     "execution_count": 146,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l5 = [\"Linear Regression model 2\", mse_reg, r2_reg]\n",
    "mlp_l6 = [\"MLP model 4\", mse_nn4, r2_nn4]\n",
    "mlp_l7 = [\"MLP model 5\", mse_nn5, r2_nn5]\n",
    "mlp_l8 = [\"MLP model 6\", mse_nn6, r2_nn6]\n",
    "data = [lr_l5, mlp_l6, mlp_l7, mlp_l8]\n",
    "df = pd.DataFrame(data, columns = ['Model', 'Mean squared error', 'r2 score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JugcWFIF7JuZ"
   },
   "source": [
    "# Overall Summary\n",
    "### Here the first four rows displays the results by the models using window size = 60 and the next four rows displays the results by the models using window size = 120. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "QrhM_KjW6azy",
    "outputId": "a8080f29-5f29-43cc-dc48-e627980efa94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean squared error</th>\n",
       "      <th>r2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression model 1</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.942926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP model 1</td>\n",
       "      <td>0.067433</td>\n",
       "      <td>0.941069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP model 2</td>\n",
       "      <td>0.069224</td>\n",
       "      <td>0.939504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP model 3</td>\n",
       "      <td>0.076219</td>\n",
       "      <td>0.931496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression model 2</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.942926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP model 4</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.933525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP model 5</td>\n",
       "      <td>0.081507</td>\n",
       "      <td>0.926736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP model 6</td>\n",
       "      <td>0.084563</td>\n",
       "      <td>0.923989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Mean squared error  r2 score\n",
       "0  Linear Regression model 1            0.065309  0.942926\n",
       "1                MLP model 1            0.067433  0.941069\n",
       "2                MLP model 2            0.069224  0.939504\n",
       "3                MLP model 3            0.076219  0.931496\n",
       "4  Linear Regression model 2            0.065309  0.942926\n",
       "5                MLP model 4            0.073954  0.933525\n",
       "6                MLP model 5            0.081507  0.926736\n",
       "7                MLP model 6            0.084563  0.923989"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [lr_l1, mlp_l2, mlp_l3, mlp_l4, lr_l5, mlp_l6, mlp_l7, mlp_l8]\n",
    "df = pd.DataFrame(data, columns = ['Model', 'Mean squared error', 'r2 score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxOqeftF7RkL"
   },
   "source": [
    "## From the above summary chart, we can see that we got comparable results using different kinds of models. Among them, we choose ***linear regression model using window size = 60*** to proceed further in our experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Er4Pae7iAc-Q"
   },
   "source": [
    "# Predicting the missing values in the given file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "X2 = np.array([0] * (window_size + 1))\n",
    "\n",
    "count = 1\n",
    "while(count<=50000):\n",
    "  row = random.randrange(len(X) - window_size - 1)\n",
    "  temp = X[row:row+window_size+1]['data'].tolist()\n",
    "  if('?' not in temp):\n",
    "    temp = [float(item) for item in temp]\n",
    "    X2 = np.vstack((X2,temp)) \n",
    "    count = count + 1\n",
    "\n",
    "X2 = X2[1:,:]\n",
    "# print(X2)\n",
    "# print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cMdc08sAjeI"
   },
   "source": [
    "## We train our data using window size of 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X2[:,0:60]\n",
    "y_train = X2[:,60]\n",
    "# print(X_train)\n",
    "# print(X_train.shape)\n",
    "# print(y_train)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRS4iTI7AqNd"
   },
   "source": [
    "## Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fgxj0Hyn9AlS",
    "outputId": "5ba706f0-d431-4f77-8251-c0ccf6e8a61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 166,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkfXMqwQAxE5"
   },
   "source": [
    "## We predict the labels of the missing values. The list of all the predicted values are printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFuh9yZ_9Ek-"
   },
   "outputs": [],
   "source": [
    "X1 = X\n",
    "X1 = np.array(X['data'])\n",
    "count = 0\n",
    "predictions = []\n",
    "for i in range(len(data)):\n",
    "  temp = X1[i]\n",
    "  if(temp == '?'):\n",
    "    if(i < window_size):\n",
    "      pred1 = np.nanmean()\n",
    "      X1[i] = pred1\n",
    "    else:\n",
    "      temp1 = np.array(X1[i-60:i].tolist())\n",
    "      temp1 = temp1.astype('float32')\n",
    "      test = temp1.reshape((1,-1))\n",
    "      pred1 = model.predict(test)\n",
    "      predictions.append(pred1[0])\n",
    "      X1[i] = pred1[0]\n",
    "    count = count + 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of assign3q4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
